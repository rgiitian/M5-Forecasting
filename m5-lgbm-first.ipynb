{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing required note\n\nimport os\nimport gc\nimport warnings\n\nimport pandas as pd\nfrom pandas.plotting import register_matplotlib_converters\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nimport joblib\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-08T16:42:02.551583Z","iopub.execute_input":"2022-12-08T16:42:02.551999Z","iopub.status.idle":"2022-12-08T16:42:03.297454Z","shell.execute_reply.started":"2022-12-08T16:42:02.551916Z","shell.execute_reply":"2022-12-08T16:42:03.296433Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# 1. Loading INPUT data","metadata":{}},{"cell_type":"code","source":"os.chdir('/kaggle/input/m5-forecasting-accuracy')\n\ncalendar = pd.read_csv('calendar.csv')\nsales_te = pd.read_csv('sales_train_evaluation.csv')\nprice = pd.read_csv('sell_prices.csv')\nsubmission = pd.read_csv('sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-12-08T01:39:38.600829Z","iopub.execute_input":"2022-12-08T01:39:38.601197Z","iopub.status.idle":"2022-12-08T01:39:48.456363Z","shell.execute_reply.started":"2022-12-08T01:39:38.601167Z","shell.execute_reply":"2022-12-08T01:39:48.454912Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"store_list = sales_te.store_id.unique()\nstore_list","metadata":{"execution":{"iopub.status.busy":"2022-12-08T01:40:11.240558Z","iopub.execute_input":"2022-12-08T01:40:11.240950Z","iopub.status.idle":"2022-12-08T01:40:11.249488Z","shell.execute_reply.started":"2022-12-08T01:40:11.240917Z","shell.execute_reply":"2022-12-08T01:40:11.248462Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array(['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1',\n       'WI_2', 'WI_3'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"#Downcast in order to save memory\n\ndef downcast(df):\n    \n    cols = df.dtypes.index.tolist()\n    types = df.dtypes.values.tolist()\n    \n    start_mem = df.memory_usage().sum() / 1024**2  \n    \n    for i,t in enumerate(types):\n        \n        if 'int' in str(t):\n            if df[cols[i]].min() > np.iinfo(np.int8).min and df[cols[i]].max() < np.iinfo(np.int8).max:\n                df[cols[i]] = df[cols[i]].astype(np.int8)\n            elif df[cols[i]].min() > np.iinfo(np.int16).min and df[cols[i]].max() < np.iinfo(np.int16).max:\n                df[cols[i]] = df[cols[i]].astype(np.int16)\n            elif df[cols[i]].min() > np.iinfo(np.int32).min and df[cols[i]].max() < np.iinfo(np.int32).max:\n                df[cols[i]] = df[cols[i]].astype(np.int32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.int64)\n        elif 'float' in str(t):\n            if df[cols[i]].min() > np.finfo(np.float16).min and df[cols[i]].max() < np.finfo(np.float16).max:\n                df[cols[i]] = df[cols[i]].astype(np.float16)\n            elif df[cols[i]].min() > np.finfo(np.float32).min and df[cols[i]].max() < np.finfo(np.float32).max:\n                df[cols[i]] = df[cols[i]].astype(np.float32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.float64)\n        elif t == np.object:\n            if cols[i] == 'date':\n                df[cols[i]] = pd.to_datetime(df[cols[i]], format='%Y-%m-%d')\n            else:\n                df[cols[i]] = df[cols[i]].astype('category')\n    end_mem = df.memory_usage().sum() / 1024**2           \n    print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n\n    return df  ","metadata":{"execution":{"iopub.status.busy":"2022-12-08T00:11:01.913267Z","iopub.status.idle":"2022-12-08T00:11:01.913614Z","shell.execute_reply.started":"2022-12-08T00:11:01.913441Z","shell.execute_reply":"2022-12-08T00:11:01.913456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"calendar = downcast(calendar)\nsales_te = downcast(sales_te)\nprice = downcast(price)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T00:11:01.915007Z","iopub.status.idle":"2022-12-08T00:11:01.915325Z","shell.execute_reply.started":"2022-12-08T00:11:01.915164Z","shell.execute_reply":"2022-12-08T00:11:01.915178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales_te.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T00:11:01.916647Z","iopub.status.idle":"2022-12-08T00:11:01.917427Z","shell.execute_reply.started":"2022-12-08T00:11:01.917259Z","shell.execute_reply":"2022-12-08T00:11:01.917276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concating the test rows \n\ndf_sales_te = pd.melt(sales_te, id_vars = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name = 'day', value_name = 'demand')\n\neval_rows = [row for row in submission['id'] if 'evaluation' in row]\ndf_eval = submission[submission['id'].isin(eval_rows)]\n\ndf_eval.columns = ['id', 'd_1942', 'd_1943', 'd_1944', 'd_1945', 'd_1946', 'd_1947', 'd_1948', 'd_1949', 'd_1950', 'd_1951', 'd_1952', 'd_1953', 'd_1954', 'd_1955', 'd_1956', 'd_1957', 'd_1958', 'd_1959', \n                  'd_1960', 'd_1961', 'd_1962', 'd_1963', 'd_1964', 'd_1965', 'd_1966', 'd_1967', 'd_1968', 'd_1969']\n\nproduct = df_sales_te[['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']].drop_duplicates()\n\n\n# df_eval['id'] = df_eval['id'].str.replace('_evaluation','_validation')\ndf_eval = df_eval.merge(product, how = 'left', on = 'id')\n# df_eval['id'] = df_eval['id'].str.replace('_validation','_evaluation')\n\n\ndf_eval = pd.melt(df_eval, id_vars = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name = 'day', value_name = 'demand')\ndf_sales_te = pd.concat([df_sales_te, df_eval], axis = 0)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-08T00:11:01.918236Z","iopub.status.idle":"2022-12-08T00:11:01.918976Z","shell.execute_reply.started":"2022-12-08T00:11:01.918822Z","shell.execute_reply":"2022-12-08T00:11:01.918839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sales_te.tail()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T00:11:01.919715Z","iopub.status.idle":"2022-12-08T00:11:01.920433Z","shell.execute_reply.started":"2022-12-08T00:11:01.920250Z","shell.execute_reply":"2022-12-08T00:11:01.920268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# \ncalendar.drop(['weekday', 'wday', 'month', 'year'], inplace = True, axis = 1)\ndf_te = pd.merge(df_sales_te, calendar, how = 'left', left_on = ['day'], right_on = ['d'])\ndf_te = pd.merge(df_te, price, on = ['store_id', 'item_id', 'wm_yr_wk'], how = 'left')\ndf_te.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T00:11:01.922917Z","iopub.status.idle":"2022-12-08T00:11:01.923205Z","shell.execute_reply.started":"2022-12-08T00:11:01.923063Z","shell.execute_reply":"2022-12-08T00:11:01.923077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_te.tail()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T00:11:01.924360Z","iopub.status.idle":"2022-12-08T00:11:01.924672Z","shell.execute_reply.started":"2022-12-08T00:11:01.924505Z","shell.execute_reply":"2022-12-08T00:11:01.924519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del sales_te, df_sales_te, calendar, price\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T00:11:01.929400Z","iopub.status.idle":"2022-12-08T00:11:01.929726Z","shell.execute_reply.started":"2022-12-08T00:11:01.929545Z","shell.execute_reply":"2022-12-08T00:11:01.929559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Feature Engineering","metadata":{}},{"cell_type":"code","source":"def demand_features(df):\n    \n    df['lag_t28'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28))\n    df['lag_t29'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(29))\n    df['lag_t30'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(30))\n    df['rolling_mean_t7'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(7).mean())\n    df['rolling_std_t7'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(7).std())\n    df['rolling_mean_t30'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(30).mean())\n    df['rolling_mean_t90'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(90).mean())\n    df['rolling_mean_t180'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(180).mean())\n    df['rolling_std_t30'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(30).std())\n    df['rolling_skew_t30'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(30).skew())\n    df['rolling_kurt_t30'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(30).kurt())\n    \n    return df\n\ndef seasonal_features(df):\n    df['date'] = pd.to_datetime(df['date'])\n    df['year'] = df['date'].dt.year\n    df['month'] = df['date'].dt.month\n    df['weekofyear'] = df['date'].dt.week\n    df['dayofmonth'] = df['date'].dt.day\n    df['dayofweek'] = df['date'].dt.dayofweek\n    df['weekofmonth'] = df['dayofmonth'].apply(lambda x: ((x - 1)//7 + 1))\n    \n    return df\n\ndef price_features(df):\n    df['lag_price_t1'] = (df.groupby(['id'])['sell_price'].transform(lambda x: x.shift(1))).round(2)\n    df['price_change_t1'] = (df['lag_price_t1'] - df['sell_price']) / (df['lag_price_t1'])\n    df['rolling_price_max_t365'] = df.groupby(['id'])['sell_price'].transform(lambda x: x.shift(1).rolling(365).max())\n    df['price_change_t365'] = (df['rolling_price_max_t365'] - df['sell_price']) / (df['rolling_price_max_t365'])\n    df['rolling_price_std_t7'] = df.groupby(['id'])['sell_price'].transform(lambda x: x.rolling(7).std())\n    df['rolling_price_std_t30'] = df.groupby(['id'])['sell_price'].transform(lambda x: x.rolling(30).std())\n    df.drop(['rolling_price_max_t365', 'lag_price_t1'], inplace = True, axis = 1)\n    \n    return df\n\ndef gen_features(df):\n    df = demand_features(df)\n    df = seasonal_features(df)\n    df = price_features(df)\n    \n    return df\n\ndef cat_encode(df):\n    \n    cat_cols = ['item_id', 'dept_id', 'cat_id', 'state_id', 'event_name_1', 'event_name_2']\n    for col in cat_cols:\n        encoder = LabelEncoder()\n        df[col] = encoder.fit_transform(df[col])\n    \n    return df\n","metadata":{"execution":{"iopub.status.busy":"2022-12-08T00:11:01.935996Z","iopub.status.idle":"2022-12-08T00:11:01.936808Z","shell.execute_reply.started":"2022-12-08T00:11:01.936625Z","shell.execute_reply":"2022-12-08T00:11:01.936645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_te.info()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T00:11:01.939399Z","iopub.status.idle":"2022-12-08T00:11:01.939717Z","shell.execute_reply.started":"2022-12-08T00:11:01.939554Z","shell.execute_reply":"2022-12-08T00:11:01.939568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generating features by store to limit the usage of memory\n\n\n# Directory to save the pickle files\nos.mkdir('/kaggle/working/DataFeatures')\n\ndf_te.drop(columns = ['event_type_1', 'event_type_2', 'day', 'wm_yr_wk'], inplace = True)\n\nstore_list = list(df_te.store_id.unique())\n\nfor store in store_list:\n    globals()['df_' + str(store)] = df_te[df_te.store_id == store]\n    globals()['df_' + str(store)] = gen_features(globals()['df_' + str(store)])\n    print('Features generated for store - '+str(store))\n    flt_features = [col for col in globals()['df_' + str(store)].columns if '_t' in col]\n    print(flt_features)\n    for ftr in flt_features:\n        globals()['df_' + str(store)][ftr] = globals()['df_' + str(store)][ftr].apply(lambda x: round(x, 2))\n        \n    globals()['df_' + str(store)] = cat_encode(globals()['df_' + str(store)])   \n    \n    globals()['df_' + str(store)] = downcast(globals()['df_' + str(store)])    \n    \n    globals()['df_' + str(store)].to_pickle('/kaggle/working/DataFeatures/data_'+str(store)+'.pkl')\n#     del globals()['df_' + str(store)]\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-12-08T04:07:45.695635Z","iopub.execute_input":"2022-12-08T04:07:45.696341Z","iopub.status.idle":"2022-12-08T04:07:45.701169Z","shell.execute_reply.started":"2022-12-08T04:07:45.696301Z","shell.execute_reply":"2022-12-08T04:07:45.700145Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"df_CA_1.tail()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T00:11:01.941773Z","iopub.status.idle":"2022-12-08T00:11:01.942049Z","shell.execute_reply.started":"2022-12-08T00:11:01.941914Z","shell.execute_reply":"2022-12-08T00:11:01.941926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Downloading the data features as a pickle files from output directory\n\nimport zipfile\nfrom IPython.display import FileLink\n\ndef zip_dir(directory = '/kaggle/working/DataFeatures', file_name = 'DataFeatures.zip'):\n    print(directory)\n    \"\"\"\n    zip all the files in a directory\n       \n    Returns\n    _____\n    Creates a hyperlink, which can be used to download the zip file)\n    \"\"\"\n    os.chdir(directory)\n    zip_ref = zipfile.ZipFile(file_name, mode='w')\n    for folder, _, files in os.walk(directory):\n        for file in files:\n            if file_name in file:\n                pass\n            else:\n                zip_ref.write(os.path.join(folder, file))\n\n    return FileLink(file_name)\n\n\n!zip -r DataFeatures.zip /kaggle/working/DataFeatures\n\nzip_dir()\n","metadata":{"execution":{"iopub.status.busy":"2022-12-08T00:11:01.942748Z","iopub.status.idle":"2022-12-08T00:11:01.943013Z","shell.execute_reply.started":"2022-12-08T00:11:01.942882Z","shell.execute_reply":"2022-12-08T00:11:01.942894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Hypertuning the LightGBM parameters","metadata":{}},{"cell_type":"code","source":"from hyperopt import hp, tpe\nfrom hyperopt.fmin import fmin\nfrom sklearn.metrics import make_scorer\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.metrics import make_scorer\nfrom lightgbm import LGBMRegressor as lgbr\nfrom sklearn.metrics import mean_squared_error\n\n\ndef hypertune_lgb(data) :\n    \n    \n    ftrs = data.columns\n    ftrs = list(set(ftrs) - set(['d', 'date', 'demand', 'store_id', 'id']))\n    \n    \n    X_train = data[(data.d < 1914)]\n    y_train = X_train['demand']\n    X_train = X_train[ftrs]\n    \n    \n    param_grid = {'n_estimators':hp.quniform('n_estimators', 900, 1200, 100),\n               'learning_rate':hp.quniform('learning_rate', 0.1, 0.4, 0.1),\n               'max_depth':hp.quniform('max_depth', 4,8,1),\n               'num_leaves':hp.quniform('num_leaves', 25,75,25),\n               'colsample_bytree':hp.quniform('colsample_bytree', 0.5, 0.9, 0.1)\n\n              }\n\n    def objective_grid(params):\n        \n        params = {'n_estimators': int(params['n_estimators']),\n                  'learning_rate': params['learning_rate'],\n                  'max_depth': int(params['max_depth']),\n                  'num_leaves': int(params['num_leaves']),\n                  'colsample_bytree': params['colsample_bytree']\n\n                 }\n\n        lgb_model = lgbr(**params)\n        score = cross_val_score(lgb_model, X_train, y_train, cv=StratifiedKFold(),\n                                scoring=make_scorer(mean_squared_error, greater_is_better=False), n_jobs=-1).mean()\n\n\n    #Running through 10 iterations to identify the best params\n    bestParams = fmin(fn=objective_grid, space= param_grid, max_evals=10 , algo=tpe.suggest)\n    \n    return bestParams\n\n\n\n#Identifying the best parameters for 1 store  (using subset of store data)\n\nfor store in store_list :\n    print('*****Prediction for Store: {}*****'.format(store))\n    df = pd.read_pickle(\"/kaggle/input/M5-CustomFeatures2/data_\"+str(store)+\".pkl\")\n    \n    df_filter = pretrain_filter(df, 1600)\n    \n    best = hypertune_lgb(df_filter)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-08T03:09:45.187713Z","iopub.execute_input":"2022-12-08T03:09:45.188757Z","iopub.status.idle":"2022-12-08T03:09:45.195642Z","shell.execute_reply.started":"2022-12-08T03:09:45.188714Z","shell.execute_reply":"2022-12-08T03:09:45.194419Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T01:37:14.306826Z","iopub.status.idle":"2022-12-08T01:37:14.307312Z","shell.execute_reply.started":"2022-12-08T01:37:14.307061Z","shell.execute_reply":"2022-12-08T01:37:14.307085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Training LightGBM model ","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\n\ndef train_lightGBM(df):\n    \n    # Features to be included for model training\n    ftrList = df.columns\n    ftrList = list(set(ftrList) - set(['d', 'date', 'demand', 'store_id', 'id']))\n    \n    print(ftrList)\n    \n    # Train - Valid split\n    x_train = df[(df.d < 1914)]\n    y_train = x_train['demand']\n    \n    x_val = df[(df.d >= 1914) & (df.d < 1942)]\n    y_val = x_val['demand']\n    \n    x_train.shape\n    \n    \n    x_test = df[(df.d >= 1942)]\n#     del dte\n#     gc.collect()\n\n    # parammeters\n    params = {\n        'boosting_type': 'gbdt',\n        'metric': 'rmse',\n        'objective': 'huber',\n#         'objective': 'tweedie',\n#         'tweedie_variance_power': 1.1,\n        'n_jobs': -1,\n        'seed': 236,\n        'bagging_fraction': 0.75,\n        'lambda_l2' : 0.1,\n        'bagging_freq': 10, \n        'tree_learner':'voting',\n        'device' : 'gpu',\n        'gpu_platform_id' : 0,\n        'gpu_device_id': 0\n    }\n    \n    # Tuned Hyperparametrs\n    \n    params_2  = {\n            'n_estimators': 550,\n           'max_depth': 6,\n           'num_leaves': 30,\n           'colsample_bytree': 0.75,\n            'learning_rate': 0.1   \n        }\n        \n    params.update(params_2)\n\n    train_set = lgb.Dataset(x_train[ftrList], y_train)\n    val_set = lgb.Dataset(x_val[ftrList], y_val)\n    \n    print(x_val.shape)\n    \n#     del x_train, y_train\n    \n    \n\n    model = lgb.train(params, train_set, num_boost_round = 2500, early_stopping_rounds = 50,\n                      valid_sets = [train_set, val_set], verbose_eval = 100)\n#     model = lgb.LGBMRegressor.fit(params, x_train, y_train, eval_set=[(x_train,y_train),(x_val,y_val)], early_stopping_rounds = 50, verbose = 20)\n\n    val_pred = model.predict(x_val[ftrList])\n    val_score = np.sqrt(mean_squared_error(val_pred, y_val))\n    print(f'Our val rmse score is {val_score}')\n    y_pred = model.predict(x_test[ftrList])\n    x_test['demand'] = y_pred\n      \n    # Returning both model and test data predictions\n    return x_test, model\n","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:25:13.978316Z","iopub.execute_input":"2022-12-08T05:25:13.978707Z","iopub.status.idle":"2022-12-08T05:25:13.990327Z","shell.execute_reply.started":"2022-12-08T05:25:13.978672Z","shell.execute_reply":"2022-12-08T05:25:13.989309Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"store_list[-3:-2]","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:14:44.005279Z","iopub.execute_input":"2022-12-08T05:14:44.005642Z","iopub.status.idle":"2022-12-08T05:14:44.012235Z","shell.execute_reply.started":"2022-12-08T05:14:44.005607Z","shell.execute_reply":"2022-12-08T05:14:44.011209Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"array(['WI_1'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"# Training models - store-wise (10 models)\n# Saving the output to df_test_{store_id} and also model to model_{store_id}\n\n\n\n# final_sub = pd.DataFrame(columns = submission.columns)\n\n# ftrList = list(df_te.columns)\n# ftrList = list(set(ftrList) - set(['d', 'date', 'demand', 'store_id', 'id']))\n# len(ftrList)\n\n\nfor store in store_list:\n    print('*****Prediction for Store: {}*****'.format(store))\n    globals()['df_'+ str(store)] = pd.read_pickle(\"/kaggle/input/M5-CustomFeatures2/data_\"+str(store)+\".pkl\")\n    \n    \n    \n    globals()['df_'+ str(store)] = pretrain_filter(globals()['df_'+ str(store)], 850)\n    \n    ftrList = list(globals()['df_'+ str(store)].columns)\n    ftrList = list(set(ftrList) - set(['d', 'date', 'demand', 'store_id', 'id']))\n \n\n\n    globals()['df_test_'+ str(store)], globals()['model_'+ str(store)] = train_lightGBM(globals()['df_'+ str(store)])\n    \n#     joblib.dump(globals()['model_'+ str(store)], '/kaggle/working/model_'+str(store)+'.pkl')\n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:25:21.890413Z","iopub.execute_input":"2022-12-08T05:25:21.890803Z","iopub.status.idle":"2022-12-08T05:51:29.964900Z","shell.execute_reply.started":"2022-12-08T05:25:21.890749Z","shell.execute_reply":"2022-12-08T05:51:29.964039Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"*****Prediction for Store: CA_1*****\n['snap_WI', 'rolling_mean_t90', 'lag_t30', 'rolling_price_std_t30', 'snap_TX', 'month', 'weekofmonth', 'rolling_std_t30', 'sell_price', 'rolling_kurt_t30', 'lag_t29', 'year', 'dayofweek', 'price_change_t1', 'rolling_mean_t180', 'lag_t28', 'event_name_1', 'dayofmonth', 'rolling_mean_t30', 'dept_id', 'rolling_std_t7', 'weekofyear', 'item_id', 'rolling_price_std_t7', 'rolling_mean_t7', 'snap_CA', 'rolling_skew_t30', 'cat_id', 'state_id', 'event_name_2', 'price_change_t365']\n(85372, 36)\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 3220\n[LightGBM] [Info] Number of data points in the train set: 3241087, number of used features: 30\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (74.18 MB) transferred to GPU in 0.099530 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 1.437146\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.68 MB) transferred to GPU in 0.078403 secs. 1 sparse feature groups\nTraining until validation scores don't improve for 50 rounds\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.073948 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.074812 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.093372 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.074994 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.075975 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.075924 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.076068 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.62 MB) transferred to GPU in 0.075463 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.077719 secs. 1 sparse feature groups\n[100]\ttraining's rmse: 3.32837\tvalid_1's rmse: 2.92497\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.61 MB) transferred to GPU in 0.075664 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.65 MB) transferred to GPU in 0.075820 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.075425 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.075164 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.075404 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.076709 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.076171 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.65 MB) transferred to GPU in 0.075984 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.66 MB) transferred to GPU in 0.087543 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.67 MB) transferred to GPU in 0.075112 secs. 1 sparse feature groups\n[200]\ttraining's rmse: 3.07221\tvalid_1's rmse: 2.67019\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.076777 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.075343 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.075177 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.65 MB) transferred to GPU in 0.075614 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.075683 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.61 MB) transferred to GPU in 0.121551 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.075065 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.60 MB) transferred to GPU in 0.073377 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.60 MB) transferred to GPU in 0.074286 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.075768 secs. 1 sparse feature groups\n[300]\ttraining's rmse: 2.9271\tvalid_1's rmse: 2.54274\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.59 MB) transferred to GPU in 0.076669 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.085051 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.66 MB) transferred to GPU in 0.075850 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.111580 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.62 MB) transferred to GPU in 0.074990 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.62 MB) transferred to GPU in 0.079506 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.075776 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.65 MB) transferred to GPU in 0.075482 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.075460 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.61 MB) transferred to GPU in 0.075131 secs. 1 sparse feature groups\n[400]\ttraining's rmse: 2.83463\tvalid_1's rmse: 2.46467\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.66 MB) transferred to GPU in 0.077766 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.076184 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.086347 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.075643 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.66 MB) transferred to GPU in 0.075734 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.075490 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.66 MB) transferred to GPU in 0.075372 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.075208 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.62 MB) transferred to GPU in 0.075068 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.076218 secs. 1 sparse feature groups\n[500]\ttraining's rmse: 2.76864\tvalid_1's rmse: 2.41727\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.65 MB) transferred to GPU in 0.077051 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.075786 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.075453 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.075180 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.075692 secs. 1 sparse feature groups\nDid not meet early stopping. Best iteration is:\n[550]\ttraining's rmse: 2.74175\tvalid_1's rmse: 2.40064\nOur val rmse score is 2.40064081131279\n*****Prediction for Store: CA_2*****\n['snap_WI', 'rolling_mean_t90', 'lag_t30', 'rolling_price_std_t30', 'snap_TX', 'month', 'weekofmonth', 'rolling_std_t30', 'sell_price', 'rolling_kurt_t30', 'lag_t29', 'year', 'dayofweek', 'price_change_t1', 'rolling_mean_t180', 'lag_t28', 'event_name_1', 'dayofmonth', 'rolling_mean_t30', 'dept_id', 'rolling_std_t7', 'weekofyear', 'item_id', 'rolling_price_std_t7', 'rolling_mean_t7', 'snap_CA', 'rolling_skew_t30', 'cat_id', 'state_id', 'event_name_2', 'price_change_t365']\n(85372, 36)\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 3137\n[LightGBM] [Info] Number of data points in the train set: 3241087, number of used features: 30\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (61.82 MB) transferred to GPU in 0.087722 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 1.048018\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.40 MB) transferred to GPU in 0.065489 secs. 1 sparse feature groups\nTraining until validation scores don't improve for 50 rounds\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.067402 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066808 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066761 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066866 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.067180 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.067061 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066305 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.089827 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066877 secs. 1 sparse feature groups\n[100]\ttraining's rmse: 2.26242\tvalid_1's rmse: 2.58254\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.068020 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.066641 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.068961 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.067249 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066731 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066748 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.068013 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.068116 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.066865 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.39 MB) transferred to GPU in 0.079587 secs. 1 sparse feature groups\n[200]\ttraining's rmse: 2.11349\tvalid_1's rmse: 2.36985\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.068514 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.085170 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.067482 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.082520 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.067160 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.070615 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.067521 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.070187 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.120539 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066506 secs. 1 sparse feature groups\n[300]\ttraining's rmse: 2.03831\tvalid_1's rmse: 2.2637\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.069092 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.067226 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.067247 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.066421 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.066908 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.066765 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.066389 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.067039 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.101772 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.070601 secs. 1 sparse feature groups\n[400]\ttraining's rmse: 1.99535\tvalid_1's rmse: 2.20366\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.067816 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066717 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.067417 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066679 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.066731 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.066634 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.066385 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.125244 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.066595 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.067401 secs. 1 sparse feature groups\n[500]\ttraining's rmse: 1.96802\tvalid_1's rmse: 2.16884\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.067622 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.067147 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.067499 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.154185 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066987 secs. 1 sparse feature groups\nDid not meet early stopping. Best iteration is:\n[550]\ttraining's rmse: 1.95832\tvalid_1's rmse: 2.15729\nOur val rmse score is 2.157292710973983\n*****Prediction for Store: CA_3*****\n['snap_WI', 'rolling_mean_t90', 'lag_t30', 'rolling_price_std_t30', 'snap_TX', 'month', 'weekofmonth', 'rolling_std_t30', 'sell_price', 'rolling_kurt_t30', 'lag_t29', 'year', 'dayofweek', 'price_change_t1', 'rolling_mean_t180', 'lag_t28', 'event_name_1', 'dayofmonth', 'rolling_mean_t30', 'dept_id', 'rolling_std_t7', 'weekofyear', 'item_id', 'rolling_price_std_t7', 'rolling_mean_t7', 'snap_CA', 'rolling_skew_t30', 'cat_id', 'state_id', 'event_name_2', 'price_change_t365']\n(85372, 36)\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 3415\n[LightGBM] [Info] Number of data points in the train set: 3241087, number of used features: 30\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (74.18 MB) transferred to GPU in 0.097688 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 2.073229\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.68 MB) transferred to GPU in 0.075953 secs. 1 sparse feature groups\nTraining until validation scores don't improve for 50 rounds\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.073228 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.075781 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.078435 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.143125 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.073332 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.074004 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.131670 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.62 MB) transferred to GPU in 0.073722 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.074141 secs. 1 sparse feature groups\n[100]\ttraining's rmse: 5.14394\tvalid_1's rmse: 3.95612\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.61 MB) transferred to GPU in 0.075020 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.65 MB) transferred to GPU in 0.073732 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.073729 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.074411 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.073561 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.076331 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.074520 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.65 MB) transferred to GPU in 0.073741 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.66 MB) transferred to GPU in 0.077527 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.67 MB) transferred to GPU in 0.073386 secs. 1 sparse feature groups\n[200]\ttraining's rmse: 4.75039\tvalid_1's rmse: 3.60277\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.076169 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.074326 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.074167 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.65 MB) transferred to GPU in 0.077948 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.073961 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.61 MB) transferred to GPU in 0.073935 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.077508 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.60 MB) transferred to GPU in 0.073489 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.60 MB) transferred to GPU in 0.073991 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.074718 secs. 1 sparse feature groups\n[300]\ttraining's rmse: 4.49884\tvalid_1's rmse: 3.38199\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.59 MB) transferred to GPU in 0.073540 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.073473 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.66 MB) transferred to GPU in 0.085304 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.073332 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.62 MB) transferred to GPU in 0.074077 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.62 MB) transferred to GPU in 0.073641 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.074204 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.65 MB) transferred to GPU in 0.074498 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.074882 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.61 MB) transferred to GPU in 0.073534 secs. 1 sparse feature groups\n[400]\ttraining's rmse: 4.3215\tvalid_1's rmse: 3.22604\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.66 MB) transferred to GPU in 0.076194 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.073071 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.073317 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.073976 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.66 MB) transferred to GPU in 0.124270 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.073232 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.66 MB) transferred to GPU in 0.073829 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.075261 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.62 MB) transferred to GPU in 0.077359 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.074643 secs. 1 sparse feature groups\n[500]\ttraining's rmse: 4.18934\tvalid_1's rmse: 3.1104\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.65 MB) transferred to GPU in 0.074330 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.074021 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.074765 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.64 MB) transferred to GPU in 0.140545 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 21 dense feature groups (55.63 MB) transferred to GPU in 0.074944 secs. 1 sparse feature groups\nDid not meet early stopping. Best iteration is:\n[550]\ttraining's rmse: 4.13343\tvalid_1's rmse: 3.0633\nOur val rmse score is 3.06329633414381\n*****Prediction for Store: CA_4*****\n['snap_WI', 'rolling_mean_t90', 'lag_t30', 'rolling_price_std_t30', 'snap_TX', 'month', 'weekofmonth', 'rolling_std_t30', 'sell_price', 'rolling_kurt_t30', 'lag_t29', 'year', 'dayofweek', 'price_change_t1', 'rolling_mean_t180', 'lag_t28', 'event_name_1', 'dayofmonth', 'rolling_mean_t30', 'dept_id', 'rolling_std_t7', 'weekofyear', 'item_id', 'rolling_price_std_t7', 'rolling_mean_t7', 'snap_CA', 'rolling_skew_t30', 'cat_id', 'state_id', 'event_name_2', 'price_change_t365']\n(85372, 36)\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 3005\n[LightGBM] [Info] Number of data points in the train set: 3241087, number of used features: 30\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (61.82 MB) transferred to GPU in 0.088734 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 0.779062\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.40 MB) transferred to GPU in 0.066420 secs. 1 sparse feature groups\nTraining until validation scores don't improve for 50 rounds\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065234 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065615 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065468 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065036 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.113387 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065164 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065413 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.065381 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.152468 secs. 1 sparse feature groups\n[100]\ttraining's rmse: 1.64179\tvalid_1's rmse: 1.58162\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.067841 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065717 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065682 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065989 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065698 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066301 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.096077 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065509 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065707 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.39 MB) transferred to GPU in 0.065392 secs. 1 sparse feature groups\n[200]\ttraining's rmse: 1.5681\tvalid_1's rmse: 1.52849\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.068081 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066006 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066058 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.066027 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.066000 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.066047 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.143646 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.068019 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.065298 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.067322 secs. 1 sparse feature groups\n[300]\ttraining's rmse: 1.53488\tvalid_1's rmse: 1.51666\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.065699 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066394 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065104 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.066122 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.065140 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.137192 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.065168 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065258 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065574 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.066034 secs. 1 sparse feature groups\n[400]\ttraining's rmse: 1.51516\tvalid_1's rmse: 1.51144\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.067157 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065689 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.064754 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.064912 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065488 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065509 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065447 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.066493 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.065387 secs. 1 sparse feature groups\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065592 secs. 1 sparse feature groups\n[500]\ttraining's rmse: 1.5041\tvalid_1's rmse: 1.50746\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065723 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065430 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.067988 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.130901 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065695 secs. 1 sparse feature groups\nDid not meet early stopping. Best iteration is:\n[550]\ttraining's rmse: 1.49991\tvalid_1's rmse: 1.5062\nOur val rmse score is 1.5061985371506696\n*****Prediction for Store: TX_1*****\n['snap_WI', 'rolling_mean_t90', 'lag_t30', 'rolling_price_std_t30', 'snap_TX', 'month', 'weekofmonth', 'rolling_std_t30', 'sell_price', 'rolling_kurt_t30', 'lag_t29', 'year', 'dayofweek', 'price_change_t1', 'rolling_mean_t180', 'lag_t28', 'event_name_1', 'dayofmonth', 'rolling_mean_t30', 'dept_id', 'rolling_std_t7', 'weekofyear', 'item_id', 'rolling_price_std_t7', 'rolling_mean_t7', 'snap_CA', 'rolling_skew_t30', 'cat_id', 'state_id', 'event_name_2', 'price_change_t365']\n(85372, 36)\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 3373\n[LightGBM] [Info] Number of data points in the train set: 3241087, number of used features: 30\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (61.82 MB) transferred to GPU in 0.089402 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 1.016833\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.40 MB) transferred to GPU in 0.065600 secs. 1 sparse feature groups\nTraining until validation scores don't improve for 50 rounds\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066295 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065342 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.076377 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066012 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.131388 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065885 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.067579 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.070435 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.147987 secs. 1 sparse feature groups\n[100]\ttraining's rmse: 2.67099\tvalid_1's rmse: 2.48185\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.066472 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065176 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065492 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065726 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065866 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065431 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.131702 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065369 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065442 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.39 MB) transferred to GPU in 0.066707 secs. 1 sparse feature groups\n[200]\ttraining's rmse: 2.46362\tvalid_1's rmse: 2.22718\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066832 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066600 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065483 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065080 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065225 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.066393 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066798 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.066626 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.065939 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065387 secs. 1 sparse feature groups\n[300]\ttraining's rmse: 2.34682\tvalid_1's rmse: 2.08707\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.067029 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065293 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.066142 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065817 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.065770 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.067555 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.066175 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065844 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065987 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.065721 secs. 1 sparse feature groups\n[400]\ttraining's rmse: 2.27205\tvalid_1's rmse: 1.99896\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.067245 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065581 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065138 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065231 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065485 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.066906 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.066158 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065172 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.065607 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065668 secs. 1 sparse feature groups\n[500]\ttraining's rmse: 2.2226\tvalid_1's rmse: 1.94152\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.066430 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065709 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065793 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065061 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065202 secs. 1 sparse feature groups\nDid not meet early stopping. Best iteration is:\n[550]\ttraining's rmse: 2.20603\tvalid_1's rmse: 1.92214\nOur val rmse score is 1.9221373516794904\n*****Prediction for Store: TX_2*****\n['snap_WI', 'rolling_mean_t90', 'lag_t30', 'rolling_price_std_t30', 'snap_TX', 'month', 'weekofmonth', 'rolling_std_t30', 'sell_price', 'rolling_kurt_t30', 'lag_t29', 'year', 'dayofweek', 'price_change_t1', 'rolling_mean_t180', 'lag_t28', 'event_name_1', 'dayofmonth', 'rolling_mean_t30', 'dept_id', 'rolling_std_t7', 'weekofyear', 'item_id', 'rolling_price_std_t7', 'rolling_mean_t7', 'snap_CA', 'rolling_skew_t30', 'cat_id', 'state_id', 'event_name_2', 'price_change_t365']\n(85372, 36)\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 3481\n[LightGBM] [Info] Number of data points in the train set: 3241087, number of used features: 30\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (61.82 MB) transferred to GPU in 0.089986 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 1.260621\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.40 MB) transferred to GPU in 0.066720 secs. 1 sparse feature groups\nTraining until validation scores don't improve for 50 rounds\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066248 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065877 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.118471 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.064827 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065231 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065409 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065258 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.065672 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.064989 secs. 1 sparse feature groups\n[100]\ttraining's rmse: 3.61081\tvalid_1's rmse: 3.00306\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.066324 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.064889 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065059 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065097 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065142 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065113 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.064799 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.064860 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.170909 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.39 MB) transferred to GPU in 0.065554 secs. 1 sparse feature groups\n[200]\ttraining's rmse: 3.32179\tvalid_1's rmse: 2.67971\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066946 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065800 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065494 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.064683 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065416 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.065184 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065334 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.065066 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.065477 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065840 secs. 1 sparse feature groups\n[300]\ttraining's rmse: 3.12632\tvalid_1's rmse: 2.48936\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.067723 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065498 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.075213 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065169 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.064878 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.065175 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.073212 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065179 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065114 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.065307 secs. 1 sparse feature groups\n[400]\ttraining's rmse: 2.97982\tvalid_1's rmse: 2.34853\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.068291 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065294 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065008 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.151353 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065265 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.066199 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065459 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065246 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.066974 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065826 secs. 1 sparse feature groups\n[500]\ttraining's rmse: 2.86852\tvalid_1's rmse: 2.24069\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.066512 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065536 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065752 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065070 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.074454 secs. 1 sparse feature groups\nDid not meet early stopping. Best iteration is:\n[550]\ttraining's rmse: 2.82236\tvalid_1's rmse: 2.19803\nOur val rmse score is 2.1980270544784197\n*****Prediction for Store: TX_3*****\n['snap_WI', 'rolling_mean_t90', 'lag_t30', 'rolling_price_std_t30', 'snap_TX', 'month', 'weekofmonth', 'rolling_std_t30', 'sell_price', 'rolling_kurt_t30', 'lag_t29', 'year', 'dayofweek', 'price_change_t1', 'rolling_mean_t180', 'lag_t28', 'event_name_1', 'dayofmonth', 'rolling_mean_t30', 'dept_id', 'rolling_std_t7', 'weekofyear', 'item_id', 'rolling_price_std_t7', 'rolling_mean_t7', 'snap_CA', 'rolling_skew_t30', 'cat_id', 'state_id', 'event_name_2', 'price_change_t365']\n(85372, 36)\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 3379\n[LightGBM] [Info] Number of data points in the train set: 3241087, number of used features: 30\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (61.82 MB) transferred to GPU in 0.107370 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 1.145015\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.40 MB) transferred to GPU in 0.070719 secs. 1 sparse feature groups\nTraining until validation scores don't improve for 50 rounds\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.073970 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.102209 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065985 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065860 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.066105 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065993 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065767 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.076986 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.064878 secs. 1 sparse feature groups\n[100]\ttraining's rmse: 3.12138\tvalid_1's rmse: 2.96477\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.066968 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.068081 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065715 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065468 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065270 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.139043 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065559 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065320 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065191 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.39 MB) transferred to GPU in 0.065574 secs. 1 sparse feature groups\n[200]\ttraining's rmse: 2.85771\tvalid_1's rmse: 2.66586\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.067309 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.100432 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.075902 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.064832 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065445 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.065074 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065609 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.064880 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.066411 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065971 secs. 1 sparse feature groups\n[300]\ttraining's rmse: 2.68829\tvalid_1's rmse: 2.49088\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.067402 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065793 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.066612 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.067327 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.067305 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.066292 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.065851 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065543 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065136 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.082824 secs. 1 sparse feature groups\n[400]\ttraining's rmse: 2.56944\tvalid_1's rmse: 2.3741\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.066673 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065397 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065643 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.064956 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065096 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065392 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065765 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065227 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.065435 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.064838 secs. 1 sparse feature groups\n[500]\ttraining's rmse: 2.48287\tvalid_1's rmse: 2.29276\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065923 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.064986 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.074832 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065181 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065476 secs. 1 sparse feature groups\nDid not meet early stopping. Best iteration is:\n[550]\ttraining's rmse: 2.44907\tvalid_1's rmse: 2.26522\nOur val rmse score is 2.265216020173931\n*****Prediction for Store: WI_1*****\n['snap_WI', 'rolling_mean_t90', 'lag_t30', 'rolling_price_std_t30', 'snap_TX', 'month', 'weekofmonth', 'rolling_std_t30', 'sell_price', 'rolling_kurt_t30', 'lag_t29', 'year', 'dayofweek', 'price_change_t1', 'rolling_mean_t180', 'lag_t28', 'event_name_1', 'dayofmonth', 'rolling_mean_t30', 'dept_id', 'rolling_std_t7', 'weekofyear', 'item_id', 'rolling_price_std_t7', 'rolling_mean_t7', 'snap_CA', 'rolling_skew_t30', 'cat_id', 'state_id', 'event_name_2', 'price_change_t365']\n(85372, 36)\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 3187\n[LightGBM] [Info] Number of data points in the train set: 3241087, number of used features: 30\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (61.82 MB) transferred to GPU in 0.089040 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 1.075127\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.40 MB) transferred to GPU in 0.065235 secs. 1 sparse feature groups\nTraining until validation scores don't improve for 50 rounds\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066706 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065537 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065464 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.069138 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065700 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066043 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.064857 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.133535 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065159 secs. 1 sparse feature groups\n[100]\ttraining's rmse: 2.05603\tvalid_1's rmse: 2.0238\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.067503 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065915 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065328 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.111710 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065904 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065193 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065087 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.159824 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065370 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.39 MB) transferred to GPU in 0.112395 secs. 1 sparse feature groups\n[200]\ttraining's rmse: 1.92106\tvalid_1's rmse: 1.8931\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.070363 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065638 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.070646 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065512 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.066171 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.083418 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065742 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.065592 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.065030 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066611 secs. 1 sparse feature groups\n[300]\ttraining's rmse: 1.85695\tvalid_1's rmse: 1.84413\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.067547 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065453 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.066280 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.068119 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.065598 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.065797 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.065484 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065816 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065472 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.064870 secs. 1 sparse feature groups\n[400]\ttraining's rmse: 1.82242\tvalid_1's rmse: 1.82481\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.066902 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066369 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065137 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065619 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065581 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.064922 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065770 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.066721 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.065410 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065208 secs. 1 sparse feature groups\n[500]\ttraining's rmse: 1.80236\tvalid_1's rmse: 1.81553\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.066495 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065485 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.067176 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065269 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065029 secs. 1 sparse feature groups\nDid not meet early stopping. Best iteration is:\n[550]\ttraining's rmse: 1.79572\tvalid_1's rmse: 1.81223\nOur val rmse score is 1.8122333427369202\n*****Prediction for Store: WI_2*****\n['snap_WI', 'rolling_mean_t90', 'lag_t30', 'rolling_price_std_t30', 'snap_TX', 'month', 'weekofmonth', 'rolling_std_t30', 'sell_price', 'rolling_kurt_t30', 'lag_t29', 'year', 'dayofweek', 'price_change_t1', 'rolling_mean_t180', 'lag_t28', 'event_name_1', 'dayofmonth', 'rolling_mean_t30', 'dept_id', 'rolling_std_t7', 'weekofyear', 'item_id', 'rolling_price_std_t7', 'rolling_mean_t7', 'snap_CA', 'rolling_skew_t30', 'cat_id', 'state_id', 'event_name_2', 'price_change_t365']\n(85372, 36)\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 3312\n[LightGBM] [Info] Number of data points in the train set: 3241087, number of used features: 30\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (61.82 MB) transferred to GPU in 0.089929 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 1.356233\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.40 MB) transferred to GPU in 0.065533 secs. 1 sparse feature groups\nTraining until validation scores don't improve for 50 rounds\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065673 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066151 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066093 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065442 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.066002 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.079842 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065778 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.066373 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065513 secs. 1 sparse feature groups\n[100]\ttraining's rmse: 3.5967\tvalid_1's rmse: 4.16838\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.066401 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065277 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065746 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.066454 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.145508 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065425 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065348 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065542 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.067676 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.39 MB) transferred to GPU in 0.065211 secs. 1 sparse feature groups\n[200]\ttraining's rmse: 3.3759\tvalid_1's rmse: 3.81225\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066563 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065383 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065308 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065727 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065495 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.065878 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065883 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.067135 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.065987 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065990 secs. 1 sparse feature groups\n[300]\ttraining's rmse: 3.25806\tvalid_1's rmse: 3.61189\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.067713 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.072320 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.067468 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065994 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.065429 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.067858 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.065204 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.066054 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.166616 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.065850 secs. 1 sparse feature groups\n[400]\ttraining's rmse: 3.18656\tvalid_1's rmse: 3.49142\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.066252 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065809 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065471 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065543 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.094717 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065572 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065681 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065880 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.065279 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066025 secs. 1 sparse feature groups\n[500]\ttraining's rmse: 3.14066\tvalid_1's rmse: 3.41377\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.067328 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065745 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065801 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.161319 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066245 secs. 1 sparse feature groups\nDid not meet early stopping. Best iteration is:\n[550]\ttraining's rmse: 3.12379\tvalid_1's rmse: 3.38872\nOur val rmse score is 3.3887189392360657\n*****Prediction for Store: WI_3*****\n['snap_WI', 'rolling_mean_t90', 'lag_t30', 'rolling_price_std_t30', 'snap_TX', 'month', 'weekofmonth', 'rolling_std_t30', 'sell_price', 'rolling_kurt_t30', 'lag_t29', 'year', 'dayofweek', 'price_change_t1', 'rolling_mean_t180', 'lag_t28', 'event_name_1', 'dayofmonth', 'rolling_mean_t30', 'dept_id', 'rolling_std_t7', 'weekofyear', 'item_id', 'rolling_price_std_t7', 'rolling_mean_t7', 'snap_CA', 'rolling_skew_t30', 'cat_id', 'state_id', 'event_name_2', 'price_change_t365']\n(85372, 36)\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 3295\n[LightGBM] [Info] Number of data points in the train set: 3241087, number of used features: 30\n[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (61.82 MB) transferred to GPU in 0.088427 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 1.042870\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.40 MB) transferred to GPU in 0.065523 secs. 1 sparse feature groups\nTraining until validation scores don't improve for 50 rounds\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066812 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.094008 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066790 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066021 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065720 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066062 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065679 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.065536 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065499 secs. 1 sparse feature groups\n[100]\ttraining's rmse: 3.02494\tvalid_1's rmse: 3.13999\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.066345 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065853 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065471 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.164809 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065900 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065639 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065986 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.066674 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.066260 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.39 MB) transferred to GPU in 0.065678 secs. 1 sparse feature groups\n[200]\ttraining's rmse: 2.77898\tvalid_1's rmse: 2.82375\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.067488 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066877 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065968 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065754 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065416 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.066116 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065710 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.066459 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.066264 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.097280 secs. 1 sparse feature groups\n[300]\ttraining's rmse: 2.62071\tvalid_1's rmse: 2.62676\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.33 MB) transferred to GPU in 0.067027 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.066096 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.067166 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.074723 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.067016 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.067742 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.066704 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065372 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065438 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.34 MB) transferred to GPU in 0.065723 secs. 1 sparse feature groups\n[400]\ttraining's rmse: 2.51628\tvalid_1's rmse: 2.49912\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.069855 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065537 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065825 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.105383 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065631 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065605 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.38 MB) transferred to GPU in 0.065662 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065783 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.35 MB) transferred to GPU in 0.067420 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065695 secs. 1 sparse feature groups\n[500]\ttraining's rmse: 2.44672\tvalid_1's rmse: 2.41137\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.067429 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065627 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065453 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.37 MB) transferred to GPU in 0.065556 secs. 1 sparse feature groups\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 18 dense feature groups (46.36 MB) transferred to GPU in 0.065476 secs. 1 sparse feature groups\nDid not meet early stopping. Best iteration is:\n[550]\ttraining's rmse: 2.42069\tvalid_1's rmse: 2.38423\nOur val rmse score is 2.38422556722696\n","output_type":"stream"}]},{"cell_type":"code","source":"del df_test_final\ndf_test_final = pd.DataFrame(columns = df_test_CA_1.columns)\n\nfor store in store_list:\n    df_test_final = df_test_final.append(globals()['df_test_'+ str(store)])\n    \ndf_test_final.shape\n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:51:59.846846Z","iopub.execute_input":"2022-12-08T05:51:59.847921Z","iopub.status.idle":"2022-12-08T05:52:00.762524Z","shell.execute_reply.started":"2022-12-08T05:51:59.847883Z","shell.execute_reply":"2022-12-08T05:52:00.761425Z"},"trusted":true},"execution_count":103,"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"(853720, 36)"},"metadata":{}}]},{"cell_type":"code","source":"df_test_final.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:52:02.136939Z","iopub.execute_input":"2022-12-08T05:52:02.137652Z","iopub.status.idle":"2022-12-08T05:52:02.167718Z","shell.execute_reply.started":"2022-12-08T05:52:02.137604Z","shell.execute_reply":"2022-12-08T05:52:02.166824Z"},"trusted":true},"execution_count":104,"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"                                     id item_id dept_id cat_id store_id  \\\n59181090  HOBBIES_1_001_CA_1_evaluation    1437       3      1     CA_1   \n59181091  HOBBIES_1_002_CA_1_evaluation    1438       3      1     CA_1   \n59181092  HOBBIES_1_003_CA_1_evaluation    1439       3      1     CA_1   \n59181093  HOBBIES_1_004_CA_1_evaluation    1440       3      1     CA_1   \n59181094  HOBBIES_1_005_CA_1_evaluation    1441       3      1     CA_1   \n\n         state_id    demand       date     d event_name_1  ...  year month  \\\n59181090        0  0.609984 2016-05-23  1942           30  ...  2016     5   \n59181091        0  0.202620 2016-05-23  1942           30  ...  2016     5   \n59181092        0  0.432644 2016-05-23  1942           30  ...  2016     5   \n59181093        0  1.311941 2016-05-23  1942           30  ...  2016     5   \n59181094        0  0.892137 2016-05-23  1942           30  ...  2016     5   \n\n         weekofyear dayofmonth  dayofweek  weekofmonth  price_change_t1  \\\n59181090         21         23          0            4              0.0   \n59181091         21         23          0            4              0.0   \n59181092         21         23          0            4              0.0   \n59181093         21         23          0            4              0.0   \n59181094         21         23          0            4              0.0   \n\n          price_change_t365  rolling_price_std_t7  rolling_price_std_t30  \n59181090                0.0                   0.0                    0.0  \n59181091                0.0                   0.0                    0.0  \n59181092                0.0                   0.0                    0.0  \n59181093                0.0                   0.0                    0.0  \n59181094                0.0                   0.0                    0.0  \n\n[5 rows x 36 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>demand</th>\n      <th>date</th>\n      <th>d</th>\n      <th>event_name_1</th>\n      <th>...</th>\n      <th>year</th>\n      <th>month</th>\n      <th>weekofyear</th>\n      <th>dayofmonth</th>\n      <th>dayofweek</th>\n      <th>weekofmonth</th>\n      <th>price_change_t1</th>\n      <th>price_change_t365</th>\n      <th>rolling_price_std_t7</th>\n      <th>rolling_price_std_t30</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>59181090</th>\n      <td>HOBBIES_1_001_CA_1_evaluation</td>\n      <td>1437</td>\n      <td>3</td>\n      <td>1</td>\n      <td>CA_1</td>\n      <td>0</td>\n      <td>0.609984</td>\n      <td>2016-05-23</td>\n      <td>1942</td>\n      <td>30</td>\n      <td>...</td>\n      <td>2016</td>\n      <td>5</td>\n      <td>21</td>\n      <td>23</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>59181091</th>\n      <td>HOBBIES_1_002_CA_1_evaluation</td>\n      <td>1438</td>\n      <td>3</td>\n      <td>1</td>\n      <td>CA_1</td>\n      <td>0</td>\n      <td>0.202620</td>\n      <td>2016-05-23</td>\n      <td>1942</td>\n      <td>30</td>\n      <td>...</td>\n      <td>2016</td>\n      <td>5</td>\n      <td>21</td>\n      <td>23</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>59181092</th>\n      <td>HOBBIES_1_003_CA_1_evaluation</td>\n      <td>1439</td>\n      <td>3</td>\n      <td>1</td>\n      <td>CA_1</td>\n      <td>0</td>\n      <td>0.432644</td>\n      <td>2016-05-23</td>\n      <td>1942</td>\n      <td>30</td>\n      <td>...</td>\n      <td>2016</td>\n      <td>5</td>\n      <td>21</td>\n      <td>23</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>59181093</th>\n      <td>HOBBIES_1_004_CA_1_evaluation</td>\n      <td>1440</td>\n      <td>3</td>\n      <td>1</td>\n      <td>CA_1</td>\n      <td>0</td>\n      <td>1.311941</td>\n      <td>2016-05-23</td>\n      <td>1942</td>\n      <td>30</td>\n      <td>...</td>\n      <td>2016</td>\n      <td>5</td>\n      <td>21</td>\n      <td>23</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>59181094</th>\n      <td>HOBBIES_1_005_CA_1_evaluation</td>\n      <td>1441</td>\n      <td>3</td>\n      <td>1</td>\n      <td>CA_1</td>\n      <td>0</td>\n      <td>0.892137</td>\n      <td>2016-05-23</td>\n      <td>1942</td>\n      <td>30</td>\n      <td>...</td>\n      <td>2016</td>\n      <td>5</td>\n      <td>21</td>\n      <td>23</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 36 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 5. Transforming the test data predictions  (d- 1942 to 1969) into submission format","metadata":{}},{"cell_type":"code","source":"\ndef predict(test, submission):\n    predictions = test[['id', 'date', 'demand']]\n    predictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'demand').reset_index()\n    predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n    validation_rows = [row for row in submission['id'] if 'evaluation' in row] \n    validation = submission[submission['id'].isin(validation_rows)]\n    validation['id'] = validation['id'].str.replace('_evaluation','_validation')\n    evaluation = submission[['id']].merge(predictions, on = 'id')\n    final = pd.concat([validation, evaluation])\n#     final.to_csv('submission.csv', index = False)\n    \n    return final\n\nsub = predict(df_test_final, submission)\n\n\n# submission = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sample_submission.csv')\n# submission","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:52:03.665162Z","iopub.execute_input":"2022-12-08T05:52:03.665527Z","iopub.status.idle":"2022-12-08T05:52:04.582154Z","shell.execute_reply.started":"2022-12-08T05:52:03.665495Z","shell.execute_reply":"2022-12-08T05:52:04.581106Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('/kaggle/working/submission_hub.csv', index = False)\nsub.tail()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T05:52:40.463966Z","iopub.execute_input":"2022-12-08T05:52:40.464352Z","iopub.status.idle":"2022-12-08T05:52:41.833350Z","shell.execute_reply.started":"2022-12-08T05:52:40.464319Z","shell.execute_reply":"2022-12-08T05:52:41.832246Z"},"trusted":true},"execution_count":106,"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"                                id        F1        F2        F3        F4  \\\n30485  FOODS_3_823_WI_3_evaluation  0.268591  0.255323  0.251298  0.322343   \n30486  FOODS_3_824_WI_3_evaluation  0.159667  0.172015  0.225666  0.237938   \n30487  FOODS_3_825_WI_3_evaluation  0.427591  0.400598  0.403648  0.416184   \n30488  FOODS_3_826_WI_3_evaluation  0.651644  0.691362  0.613448  0.611846   \n30489  FOODS_3_827_WI_3_evaluation  0.488638  0.470574  0.439066  0.424163   \n\n             F5        F6        F7        F8        F9  ...       F19  \\\n30485  0.414304  0.401227  0.380940  0.301011  0.391339  ...  0.454402   \n30486  0.267842  0.292276  0.288183  0.219277  0.232293  ...  0.159918   \n30487  0.466004  0.601378  0.633713  0.460191  0.452317  ...  0.610567   \n30488  0.739375  0.907657  0.804703  0.619100  0.619090  ...  0.825607   \n30489  0.438770  0.629591  0.657121  0.505377  0.603194  ...  0.656164   \n\n            F20       F21       F22       F23       F24       F25       F26  \\\n30485  0.482919  0.596501  0.408235  0.479233  0.479493  0.415987  0.443299   \n30486  0.188728  0.188728  0.140711  0.150704  0.150704  0.164283  0.185401   \n30487  0.710513  0.720211  0.622596  0.613489  0.572602  0.507830  0.593669   \n30488  0.994348  0.950220  0.801783  1.168471  0.979524  0.808202  0.882771   \n30489  0.859605  0.734528  0.731424  1.054513  0.925136  0.823367  1.003751   \n\n            F27       F28  \n30485  0.519808  0.474259  \n30486  0.242884  0.224948  \n30487  0.629409  0.629779  \n30488  1.128162  0.934209  \n30489  1.339789  1.315974  \n\n[5 rows x 29 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>F1</th>\n      <th>F2</th>\n      <th>F3</th>\n      <th>F4</th>\n      <th>F5</th>\n      <th>F6</th>\n      <th>F7</th>\n      <th>F8</th>\n      <th>F9</th>\n      <th>...</th>\n      <th>F19</th>\n      <th>F20</th>\n      <th>F21</th>\n      <th>F22</th>\n      <th>F23</th>\n      <th>F24</th>\n      <th>F25</th>\n      <th>F26</th>\n      <th>F27</th>\n      <th>F28</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>30485</th>\n      <td>FOODS_3_823_WI_3_evaluation</td>\n      <td>0.268591</td>\n      <td>0.255323</td>\n      <td>0.251298</td>\n      <td>0.322343</td>\n      <td>0.414304</td>\n      <td>0.401227</td>\n      <td>0.380940</td>\n      <td>0.301011</td>\n      <td>0.391339</td>\n      <td>...</td>\n      <td>0.454402</td>\n      <td>0.482919</td>\n      <td>0.596501</td>\n      <td>0.408235</td>\n      <td>0.479233</td>\n      <td>0.479493</td>\n      <td>0.415987</td>\n      <td>0.443299</td>\n      <td>0.519808</td>\n      <td>0.474259</td>\n    </tr>\n    <tr>\n      <th>30486</th>\n      <td>FOODS_3_824_WI_3_evaluation</td>\n      <td>0.159667</td>\n      <td>0.172015</td>\n      <td>0.225666</td>\n      <td>0.237938</td>\n      <td>0.267842</td>\n      <td>0.292276</td>\n      <td>0.288183</td>\n      <td>0.219277</td>\n      <td>0.232293</td>\n      <td>...</td>\n      <td>0.159918</td>\n      <td>0.188728</td>\n      <td>0.188728</td>\n      <td>0.140711</td>\n      <td>0.150704</td>\n      <td>0.150704</td>\n      <td>0.164283</td>\n      <td>0.185401</td>\n      <td>0.242884</td>\n      <td>0.224948</td>\n    </tr>\n    <tr>\n      <th>30487</th>\n      <td>FOODS_3_825_WI_3_evaluation</td>\n      <td>0.427591</td>\n      <td>0.400598</td>\n      <td>0.403648</td>\n      <td>0.416184</td>\n      <td>0.466004</td>\n      <td>0.601378</td>\n      <td>0.633713</td>\n      <td>0.460191</td>\n      <td>0.452317</td>\n      <td>...</td>\n      <td>0.610567</td>\n      <td>0.710513</td>\n      <td>0.720211</td>\n      <td>0.622596</td>\n      <td>0.613489</td>\n      <td>0.572602</td>\n      <td>0.507830</td>\n      <td>0.593669</td>\n      <td>0.629409</td>\n      <td>0.629779</td>\n    </tr>\n    <tr>\n      <th>30488</th>\n      <td>FOODS_3_826_WI_3_evaluation</td>\n      <td>0.651644</td>\n      <td>0.691362</td>\n      <td>0.613448</td>\n      <td>0.611846</td>\n      <td>0.739375</td>\n      <td>0.907657</td>\n      <td>0.804703</td>\n      <td>0.619100</td>\n      <td>0.619090</td>\n      <td>...</td>\n      <td>0.825607</td>\n      <td>0.994348</td>\n      <td>0.950220</td>\n      <td>0.801783</td>\n      <td>1.168471</td>\n      <td>0.979524</td>\n      <td>0.808202</td>\n      <td>0.882771</td>\n      <td>1.128162</td>\n      <td>0.934209</td>\n    </tr>\n    <tr>\n      <th>30489</th>\n      <td>FOODS_3_827_WI_3_evaluation</td>\n      <td>0.488638</td>\n      <td>0.470574</td>\n      <td>0.439066</td>\n      <td>0.424163</td>\n      <td>0.438770</td>\n      <td>0.629591</td>\n      <td>0.657121</td>\n      <td>0.505377</td>\n      <td>0.603194</td>\n      <td>...</td>\n      <td>0.656164</td>\n      <td>0.859605</td>\n      <td>0.734528</td>\n      <td>0.731424</td>\n      <td>1.054513</td>\n      <td>0.925136</td>\n      <td>0.823367</td>\n      <td>1.003751</td>\n      <td>1.339789</td>\n      <td>1.315974</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 29 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\nimport shutil\nshutil.rmtree('/kaggle/working/DataFeatures.zip')\n\n# # os.remove(\"fi.zip\")\n\n# # os.listdir('/kaggle/working/')\n# os.mkdir('/kaggle/working/DataFeatures')\n\n# # calendar.to_pickle('DataFeatures/cal.pkl')\n","metadata":{"execution":{"iopub.status.busy":"2022-12-08T00:11:01.969402Z","iopub.status.idle":"2022-12-08T00:11:01.969724Z","shell.execute_reply.started":"2022-12-08T00:11:01.969541Z","shell.execute_reply":"2022-12-08T00:11:01.969555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for store in store_list:\n    \n#     print('*****Prediction for Store: {}*****'.format(store))\n#     globals()['df_'+ str(store)] = pd.read_pickle('/kaggle/input/M5-CustomFeatures2/data_TX_2.pkl')\n# #     df_test = pretrain_filter(globals()['df_'+ str(store)], 1941)\n#     model = joblib.load('/kaggle/input/Models/model_TX_2.pkl')\n    \n#     df_test['demand'] = model.predict(df_test[ftrList])\n    \n    \n    \n#     break\n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-08T00:11:01.975046Z","iopub.status.idle":"2022-12-08T00:11:01.975349Z","shell.execute_reply.started":"2022-12-08T00:11:01.975193Z","shell.execute_reply":"2022-12-08T00:11:01.975208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compute importances\nimportance_df = (\n    pd.DataFrame({\n        'feature_name': model_CA_1.feature_name(),\n        'importance_gain': model_CA_1.feature_importance(importance_type='gain'),\n        'importance_split': model_CA_1.feature_importance(importance_type='split'),\n    })\n    .sort_values('importance_gain', ascending=False)\n    .reset_index(drop=True)\n)\nprint(importance_df)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T04:03:56.463106Z","iopub.execute_input":"2022-12-08T04:03:56.463531Z","iopub.status.idle":"2022-12-08T04:03:56.481480Z","shell.execute_reply.started":"2022-12-08T04:03:56.463494Z","shell.execute_reply":"2022-12-08T04:03:56.480412Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"             feature_name  importance_gain  importance_split\n0        rolling_mean_t30     1.697307e+07               772\n1        rolling_mean_t90     5.035025e+06               892\n2       rolling_mean_t180     4.690806e+06              1202\n3         rolling_mean_t7     1.519796e+06               795\n4       price_change_t365     9.932589e+05               617\n5                 lag_t28     7.924144e+05               571\n6         rolling_std_t30     6.978736e+05               519\n7              sell_price     6.778739e+05              1735\n8               dayofweek     4.676320e+05               479\n9              weekofyear     3.639261e+05              1262\n10                item_id     2.707389e+05              1093\n11  rolling_price_std_t30     2.280203e+05               413\n12        price_change_t1     1.154081e+05                75\n13                lag_t29     8.725339e+04               260\n14                  month     8.503246e+04               449\n15           event_name_1     8.024874e+04               314\n16             dayofmonth     6.193984e+04               401\n17       rolling_skew_t30     5.937850e+04               457\n18         rolling_std_t7     5.667951e+04               326\n19                dept_id     5.628528e+04               205\n20                   year     5.458694e+04               364\n21       rolling_kurt_t30     5.274312e+04               480\n22   rolling_price_std_t7     2.474565e+04               112\n23                lag_t30     2.409811e+04               172\n24                 cat_id     1.831931e+04                45\n25                snap_CA     1.121287e+04                33\n26            weekofmonth     5.145514e+03                56\n27                snap_WI     1.508564e+03                14\n28                snap_TX     1.069113e+03                16\n29           event_name_2     5.412010e+01                 1\n30               state_id     0.000000e+00                 0\n","output_type":"stream"}]}]}